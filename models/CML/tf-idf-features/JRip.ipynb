{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:weka.core.jvm:JVM already running, call jvm.stop() first\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/Users/ritwikdeshpande/DLH/Project/CS598_DLH_Project/')\n",
    "import weka.core.jvm as jvm\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from weka.classifiers import Classifier\n",
    "from weka.core.converters import Loader\n",
    "from weka.core.converters import Loader\n",
    "from weka.classifiers import Evaluation\n",
    "from weka.core.classes import Random\n",
    "from dataset.preprocessing.tf_idf_all_feature_matrix_gen import TFIDFFeatureGeneration\n",
    "\n",
    "\n",
    "jvm.start()\n",
    "loader = Loader(classname=\"weka.core.converters.ArffLoader\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JRip:\n",
    "    def __init__(self, train_data):\n",
    "        self.jRip = Classifier(classname=\"weka.classifiers.rules.JRip\")\n",
    "        self.jRip.build_classifier(train_data)\n",
    "        self.evaluator = Evaluation(train_data)\n",
    "\n",
    "        \n",
    "        # print(self.x_train.shape, self.y_train.shape, self.x_test.shape, self.y_test.shape)\n",
    "    \n",
    "    def test_and_evaluate(self, train_data):\n",
    "        self.evaluator.crossvalidate_model(self.jRip, train_data, 10, Random(1))\n",
    "        f1_macro = self.evaluator.weighted_f_measure\n",
    "        f1_micro = self.evaluator.f_measure(1)\n",
    "        # print(f\"Macro F1 score: {f1_macro} and Micro F1 Score {f1_micro}\")\n",
    "        return f1_macro, f1_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "morbidities = ['Asthma', 'CAD', 'CHF', 'Depression', 'Diabetes', 'Gallstones', 'GERD', 'Gout', 'Hypercholesterolemia', 'Hypertension', 'Hypertriglyceridemia', 'OA', 'Obesity', 'OSA', 'PVD', 'Venous-Insufficiency']\n",
    "\n",
    "column_headings = [\"Morbidity Class\", \"DT_Macro F1\", \"DT_Micro F1\"]\n",
    "\n",
    "with open(\"./results/performance_JRip.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([column_headings[0], column_headings[1], column_headings[2]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asthma\n",
      "Macro F1 score: 0.9825174825174825 and Micro F1 Score 0.9285714285714286\n",
      "CAD\n",
      "Macro F1 score: 0.8987259711830168 and Micro F1 Score 0.9180327868852459\n",
      "CHF\n",
      "weka.classifiers.rules.JRip: Cannot handle unary class!\n",
      "Macro F1 score: 1 and Micro F1 Score 1\n",
      "Depression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread \"Thread-1\" weka.core.UnsupportedAttributeTypeException: weka.classifiers.rules.JRip: Cannot handle unary class!\n",
      "\tat weka.core.Capabilities.test(Capabilities.java:1045)\n",
      "\tat weka.core.Capabilities.test(Capabilities.java:1256)\n",
      "\tat weka.core.Capabilities.test(Capabilities.java:1138)\n",
      "\tat weka.core.Capabilities.testWithFail(Capabilities.java:1468)\n",
      "\tat weka.classifiers.rules.JRip.buildClassifier(JRip.java:1667)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1 score: 0.8884517586825207 and Micro F1 Score 0.6974358974358973\n",
      "Diabetes\n",
      "Macro F1 score: 0.9033889585504628 and Micro F1 Score 0.9301143583227447\n",
      "Gallstones\n",
      "Macro F1 score: 0.7979010603679358 and Micro F1 Score 0.12962962962962962\n",
      "GERD\n",
      "Macro F1 score: 0.7096519844748265 and Micro F1 Score 0.26347305389221554\n",
      "Gout\n",
      "Macro F1 score: 0.8168547115940944 and Micro F1 Score 0.1509433962264151\n",
      "Hypercholesterolemia\n",
      "Macro F1 score: 0.8625372558882932 and Micro F1 Score 0.8622754491017964\n",
      "Hypertension\n",
      "Macro F1 score: 0.9298977954416917 and Micro F1 Score 0.9549763033175356\n",
      "Hypertriglyceridemia\n",
      "Macro F1 score: 0.9187078159976607 and Micro F1 Score 0.05555555555555555\n",
      "OA\n",
      "Macro F1 score: 0.7878176793093205 and Micro F1 Score 0.2857142857142857\n",
      "Obesity\n",
      "Macro F1 score: 0.9655100837411553 and Micro F1 Score 0.9591397849462366\n",
      "OSA\n",
      "Macro F1 score: 0.9359083146599805 and Micro F1 Score 0.7764705882352941\n",
      "PVD\n",
      "Macro F1 score: 0.930035164910846 and Micro F1 Score 0.7612903225806451\n",
      "Venous-Insufficiency\n",
      "Macro F1 score: 0.882963412888604 and Micro F1 Score 0.14035087719298245\n"
     ]
    }
   ],
   "source": [
    "all_f1_macro_scores = []\n",
    "all_f1_micro_scores = []\n",
    "\n",
    "for morbidity in morbidities:\n",
    "    print(morbidity)\n",
    "    f1_macro_list = []\n",
    "    f1_micro_list = []\n",
    "    train_data = loader.load_file(f\"./dataset/train/train_{morbidity}_tfidf.arff\")\n",
    "    train_data.class_is_last()\n",
    "    try:\n",
    "        jRip_obj = JRip(train_data)\n",
    "        f1_macro, f1_micro = jRip_obj.test_and_evaluate(train_data)\n",
    "    except Exception as ex:\n",
    "        print(str(ex))\n",
    "        f1_macro = 1\n",
    "        f1_micro = 1\n",
    "    print(f\"Macro F1 score: {f1_macro} and Micro F1 Score {f1_micro}\")\n",
    "\n",
    "    row_heading = morbidity\n",
    "\n",
    "    # data to be written to the CSV file\n",
    "    data = [f1_macro, f1_micro]\n",
    "    all_f1_macro_scores.append(f1_macro)\n",
    "    all_f1_micro_scores.append(f1_micro)\n",
    "\n",
    "    with open(\"./results/performance_JRip.csv\", \"a\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        row = [row_heading]\n",
    "        row.extend(data)\n",
    "        writer.writerow(row)\n",
    "\n",
    "\n",
    "with open(\"./results/performance_JRip.csv\", \"a\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    row = [\"Overall-Average\"]\n",
    "    row.extend([sum(all_f1_macro_scores)/len(all_f1_macro_scores),  sum(all_f1_micro_scores)/len(all_f1_micro_scores) ])\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "jvm.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
