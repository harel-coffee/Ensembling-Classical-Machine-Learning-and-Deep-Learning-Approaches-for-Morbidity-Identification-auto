{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.join(os.getcwd(), '..','..', '..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:weka.core.jvm:Adding bundled jars\n",
      "DEBUG:weka.core.jvm:Classpath=['/Users/ritwikdeshpande/DLH/Project/CS598_DLH_Project/venv/lib/python3.7/site-packages/javabridge/jars/rhino-1.7R4.jar', '/Users/ritwikdeshpande/DLH/Project/CS598_DLH_Project/venv/lib/python3.7/site-packages/javabridge/jars/runnablequeue.jar', '/Users/ritwikdeshpande/DLH/Project/CS598_DLH_Project/venv/lib/python3.7/site-packages/javabridge/jars/cpython.jar', '/Users/ritwikdeshpande/DLH/Project/CS598_DLH_Project/venv/lib/python3.7/site-packages/weka/lib/python-weka-wrapper.jar', '/Users/ritwikdeshpande/DLH/Project/CS598_DLH_Project/venv/lib/python3.7/site-packages/weka/lib/weka.jar']\n",
      "DEBUG:weka.core.jvm:MaxHeapSize=default\n",
      "DEBUG:weka.core.jvm:Package support disabled\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from dataset.preprocessing.tf_idf_all_feature_matrix_gen import TFIDFFeatureGeneration\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import csv\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import weka.core.jvm as jvm\n",
    "from weka.core.converters import Loader\n",
    "from weka.filters import Filter\n",
    "from weka.attribute_selection import ASEvaluation, AttributeSelection\n",
    "from weka.classifiers import Classifier, Evaluation\n",
    "\n",
    "jvm.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, x_train, y_train, x_test, y_test, n, k):\n",
    "        self.knn = KNeighborsClassifier(n_neighbors=n)\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.k = k\n",
    "\n",
    "    def feature_selection_SelectKBest(self):\n",
    "        k_best = SelectKBest(chi2, k=self.k)\n",
    "        k_best.fit(self.x_train, self.y_train)\n",
    "        self.x_train = k_best.transform(self.x_train)\n",
    "        self.x_test = k_best.transform(self.x_test)\n",
    "        \n",
    "    def feature_selection_ExtraTreesClassifier(self):\n",
    "        clf = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "        clf.fit(self.x_train, self.y_train)\n",
    "        importances = clf.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        self.x_train = self.x_train[:, indices[:self.k]]\n",
    "        self.x_test = self.x_test[:, indices[:self.k]]\n",
    "    \n",
    "    def feature_selection_InfoGainAttributeEval(self, morbidity):\n",
    "        loader = Loader(classname=\"weka.core.converters.ArffLoader\")\n",
    "        train_data = loader.load_file(f\"./dataset/train/train_{morbidity}_tfidf.arff\")\n",
    "        train_data.class_is_last()\n",
    "\n",
    "        # Initialize attribute selection\n",
    "        eval = ASEvaluation(classname=\"weka.attributeSelection.InfoGainAttributeEval\")\n",
    "        search = AttributeSelection()\n",
    "        search.evaluator = eval\n",
    "        search.select_attributes(train_data)\n",
    "        selected_attributes = search.selected_attributes\n",
    "        filtered_attributes = np.delete(selected_attributes, [-1])\n",
    "        # print(\"Selected attributes:\", type(filtered_attributes), filtered_attributes.shape)\n",
    "\n",
    "        # Apply selected attributes to the training and testing sets\n",
    "        self.x_train = self.x_train[:, filtered_attributes]\n",
    "        self.x_test = self.x_test[:, filtered_attributes]\n",
    "\n",
    "    def train(self):\n",
    "        self.knn.fit(self.x_train, self.y_train)\n",
    "\n",
    "    def test_and_evaluate(self):\n",
    "        y_pred = self.knn.predict(self.x_test)\n",
    "        f1_macro = f1_score(self.y_test, y_pred, average='macro')\n",
    "        f1_micro = f1_score(self.y_test, y_pred, average='micro')\n",
    "        return f1_macro, f1_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "morbidities = ['Asthma', 'CAD', 'CHF', 'Depression', 'Diabetes', 'Gallstones', 'GERD', 'Gout', 'Hypercholesterolemia', 'Hypertension', 'Hypertriglyceridemia', 'OA', 'Obesity', 'OSA', 'PVD', 'Venous-Insufficiency']\n",
    "column_headings = [\"Morbidity Class\", \"KNN1_Macro F1\", \"KNN1_Micro F1\", \"KNN5_Macro F1\", \"KNN5_Micro F1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asthma\n",
      "(572, 600) (572,) Counter({0.0: 502, 1.0: 70})\n",
      "For n=1, Macro F1 score: 0.5892440024744311 and Micro F1 Score 0.8145795523290985\n",
      "For n=5, Macro F1 score: 0.5682579274393165 and Micro F1 Score 0.8759225650332729\n",
      "CAD\n",
      "(548, 600) (548,) Counter({1.0: 325, 0.0: 223})\n",
      "For n=1, Macro F1 score: 0.6159731039716542 and Micro F1 Score 0.6586195286195287\n",
      "For n=5, Macro F1 score: 0.63267944156766 and Micro F1 Score 0.6879797979797979\n",
      "CHF\n",
      "(243, 600) (243,) Counter({1.0: 243})\n",
      "For n=1, Macro F1 score: 1.0 and Micro F1 Score 1.0\n",
      "For n=5, Macro F1 score: 1.0 and Micro F1 Score 1.0\n",
      "Depression\n",
      "(582, 600) (582,) Counter({0.0: 460, 1.0: 122})\n",
      "For n=1, Macro F1 score: 0.5676511850007012 and Micro F1 Score 0.7113383985973115\n",
      "For n=5, Macro F1 score: 0.5884863629899829 and Micro F1 Score 0.7730566919929867\n",
      "Diabetes\n",
      "(567, 600) (567,) Counter({1.0: 396, 0.0: 171})\n",
      "For n=1, Macro F1 score: 0.5484186689831109 and Micro F1 Score 0.6473997493734337\n",
      "For n=5, Macro F1 score: 0.5444431574041595 and Micro F1 Score 0.6986528822055138\n",
      "Gallstones\n",
      "(593, 600) (593,) Counter({0.0: 506, 1.0: 87})\n",
      "For n=1, Macro F1 score: 0.5226768520000007 and Micro F1 Score 0.731779661016949\n",
      "For n=5, Macro F1 score: 0.4823746011044405 and Micro F1 Score 0.8279943502824858\n",
      "GERD\n",
      "(487, 600) (487,) Counter({0.0: 372, 1.0: 115})\n",
      "For n=1, Macro F1 score: 0.5047700555297736 and Micro F1 Score 0.6305272108843537\n",
      "For n=5, Macro F1 score: 0.5350642164981403 and Micro F1 Score 0.733078231292517\n",
      "Gout\n",
      "(596, 600) (596,) Counter({0.0: 518, 1.0: 78})\n",
      "For n=1, Macro F1 score: 0.5314279312532281 and Micro F1 Score 0.7716384180790961\n",
      "For n=5, Macro F1 score: 0.5404228762311318 and Micro F1 Score 0.8623446327683615\n",
      "Hypercholesterolemia\n",
      "(502, 600) (502,) Counter({1.0: 262, 0.0: 240})\n",
      "For n=1, Macro F1 score: 0.5632482666618921 and Micro F1 Score 0.5737254901960783\n",
      "For n=5, Macro F1 score: 0.5521753767817155 and Micro F1 Score 0.5717647058823528\n",
      "Hypertension\n",
      "(531, 600) (531,) Counter({1.0: 428, 0.0: 103})\n",
      "For n=1, Macro F1 score: 0.5052731744068807 and Micro F1 Score 0.7402166317260657\n",
      "For n=5, Macro F1 score: 0.5433215807699379 and Micro F1 Score 0.8136617749825298\n",
      "Hypertriglyceridemia\n",
      "(587, 600) (587,) Counter({0.0: 554, 1.0: 33})\n",
      "For n=1, Macro F1 score: 0.4999444239304302 and Micro F1 Score 0.8944769140853301\n",
      "For n=5, Macro F1 score: 0.5099689571093753 and Micro F1 Score 0.9421683226183518\n",
      "OA\n",
      "(565, 600) (565,) Counter({0.0: 467, 1.0: 98})\n",
      "For n=1, Macro F1 score: 0.5375759610297675 and Micro F1 Score 0.7361528822055139\n",
      "For n=5, Macro F1 score: 0.5026808829434459 and Micro F1 Score 0.794548872180451\n",
      "Obesity\n",
      "(553, 600) (553,) Counter({0.0: 314, 1.0: 239})\n",
      "For n=1, Macro F1 score: 0.5784494492339991 and Micro F1 Score 0.6000649350649351\n",
      "For n=5, Macro F1 score: 0.5939554011519641 and Micro F1 Score 0.6311363636363637\n",
      "OSA\n",
      "(590, 600) (590,) Counter({0.0: 506, 1.0: 84})\n",
      "For n=1, Macro F1 score: 0.6096131048226823 and Micro F1 Score 0.8118644067796611\n",
      "For n=5, Macro F1 score: 0.545712850356656 and Micro F1 Score 0.8491525423728813\n",
      "PVD\n",
      "(556, 600) (556,) Counter({0.0: 469, 1.0: 87})\n",
      "For n=1, Macro F1 score: 0.5574203014079532 and Micro F1 Score 0.7283116883116884\n",
      "For n=5, Macro F1 score: 0.5564759712324936 and Micro F1 Score 0.8112337662337662\n",
      "Venous-Insufficiency\n",
      "(526, 600) (526,) Counter({0.0: 482, 1.0: 44})\n",
      "For n=1, Macro F1 score: 0.5384933160293437 and Micro F1 Score 0.8481132075471699\n",
      "For n=5, Macro F1 score: 0.47647698920970194 and Micro F1 Score 0.9107402031930333\n"
     ]
    }
   ],
   "source": [
    "with open(\"./results/tf-idf-features/performance_KNN_AllFeatures.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([column_headings[0], column_headings[1], column_headings[2], column_headings[3], column_headings[4]])\n",
    "\n",
    "all_f1_macro1_scores = []\n",
    "all_f1_micro1_scores = []\n",
    "\n",
    "all_f1_macro5_scores = []\n",
    "all_f1_micro5_scores = []\n",
    "\n",
    "for morbidity in morbidities:\n",
    "    print(morbidity)\n",
    "    train_preprocessed_df = pd.read_csv('./dataset/train/train_data_intuitive_preprocessed.csv')\n",
    "    train_preprocessed_df = train_preprocessed_df[train_preprocessed_df[morbidity].isin([1.0, 0.0])]\n",
    "\n",
    "    X, Y, words = TFIDFFeatureGeneration(train_preprocessed_df, morbidity).tf_idf_matrix_gen()\n",
    "\n",
    "    # add KFold cross validation\n",
    "    skf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    f1_macro_list1 = []\n",
    "    f1_micro_list1 = []\n",
    "    f1_macro_list5 = []\n",
    "    f1_micro_list5 = []\n",
    "    for train_idx, val_idx in skf.split(X, Y):\n",
    "        X_train_fold, Y_train_fold = X[train_idx], Y[train_idx]\n",
    "        X_val_fold, Y_val_fold = X[val_idx], Y[val_idx]\n",
    "\n",
    "        # Training KNN using TF-IDF Representation\n",
    "        knn1_obj = KNN(X_train_fold, Y_train_fold, X_val_fold, Y_val_fold, 1, 100)\n",
    "        knn1_obj.train()\n",
    "\n",
    "        f1_macro1, f1_micro1 = knn1_obj.test_and_evaluate()\n",
    "\n",
    "        f1_macro_list1.append(f1_macro1)\n",
    "        f1_micro_list1.append(f1_micro1)\n",
    "\n",
    "        knn5_obj = KNN(X_train_fold, Y_train_fold, X_val_fold, Y_val_fold, 5, 100)\n",
    "        knn5_obj.train()\n",
    "\n",
    "        f1_macro5, f1_micro5 = knn5_obj.test_and_evaluate()\n",
    "\n",
    "        f1_macro_list5.append(f1_macro5)\n",
    "        f1_micro_list5.append(f1_micro5)\n",
    "\n",
    "    f1_macro1 = np.mean(f1_macro_list1)\n",
    "    f1_micro1 = np.mean(f1_micro_list1)\n",
    "    f1_macro5 = np.mean(f1_macro_list5)\n",
    "    f1_micro5 = np.mean(f1_micro_list5)\n",
    "\n",
    "    print(f\"For n=1, Macro F1 score: {f1_macro1} and Micro F1 Score {f1_micro1}\")\n",
    "    print(f\"For n=5, Macro F1 score: {f1_macro5} and Micro F1 Score {f1_micro5}\")\n",
    "\n",
    "    row_heading = morbidity\n",
    "\n",
    "    # data to be written to the CSV file\n",
    "    data = [f1_macro1, f1_micro1, f1_macro5, f1_micro5]\n",
    "    all_f1_macro1_scores.append(f1_macro1)\n",
    "    all_f1_micro1_scores.append(f1_micro1)\n",
    "\n",
    "    all_f1_macro5_scores.append(f1_macro5)\n",
    "    all_f1_micro5_scores.append(f1_micro5)\n",
    "\n",
    "\n",
    "    with open(\"./results/tf-idf-features/performance_KNN_AllFeatures.csv\", \"a\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        row = [row_heading]\n",
    "        row.extend(data)\n",
    "        writer.writerow(row)\n",
    "\n",
    "with open(\"./results/tf-idf-features/performance_KNN_AllFeatures.csv\", \"a\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    row = [\"Overall-Average\"]\n",
    "    row.extend([\n",
    "        sum(all_f1_macro1_scores)/len(all_f1_macro1_scores),  sum(all_f1_micro1_scores)/len(all_f1_micro1_scores),\n",
    "        sum(all_f1_macro5_scores)/len(all_f1_macro5_scores),  sum(all_f1_micro5_scores)/len(all_f1_micro5_scores) \n",
    "                ])\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asthma\n",
      "(572, 600) (572,) Counter({0.0: 502, 1.0: 70})\n",
      "For n=1, Macro F1 score: 0.5585601368072391 and Micro F1 Score 0.8268300060496067\n",
      "For n=5, Macro F1 score: 0.5125141298277824 and Micro F1 Score 0.8810949788263762\n",
      "CAD\n",
      "(548, 600) (548,) Counter({1.0: 325, 0.0: 223})\n",
      "For n=1, Macro F1 score: 0.6430374695646784 and Micro F1 Score 0.6532659932659933\n",
      "For n=5, Macro F1 score: 0.6859077413744469 and Micro F1 Score 0.6971043771043771\n",
      "CHF\n",
      "(243, 600) (243,) Counter({1.0: 243})\n",
      "For n=1, Macro F1 score: 1.0 and Micro F1 Score 1.0\n",
      "For n=5, Macro F1 score: 1.0 and Micro F1 Score 1.0\n",
      "Depression\n",
      "(582, 600) (582,) Counter({0.0: 460, 1.0: 122})\n",
      "For n=1, Macro F1 score: 0.5667215910734993 and Micro F1 Score 0.7216540035067213\n",
      "For n=5, Macro F1 score: 0.5400134021248935 and Micro F1 Score 0.7748392752776155\n",
      "Diabetes\n",
      "(567, 600) (567,) Counter({1.0: 396, 0.0: 171})\n",
      "For n=1, Macro F1 score: 0.6154540769219247 and Micro F1 Score 0.6825501253132832\n",
      "For n=5, Macro F1 score: 0.6380515625246815 and Micro F1 Score 0.7231203007518796\n",
      "Gallstones\n",
      "(593, 600) (593,) Counter({0.0: 506, 1.0: 87})\n",
      "For n=1, Macro F1 score: 0.5355687018138011 and Micro F1 Score 0.7687570621468927\n",
      "For n=5, Macro F1 score: 0.48905506663968235 and Micro F1 Score 0.839632768361582\n",
      "GERD\n",
      "(487, 600) (487,) Counter({0.0: 372, 1.0: 115})\n",
      "For n=1, Macro F1 score: 0.490309723665737 and Micro F1 Score 0.6283588435374149\n",
      "For n=5, Macro F1 score: 0.4846336417389444 and Micro F1 Score 0.7351190476190477\n",
      "Gout\n",
      "(596, 600) (596,) Counter({0.0: 518, 1.0: 78})\n",
      "For n=1, Macro F1 score: 0.4884932448407849 and Micro F1 Score 0.7782768361581921\n",
      "For n=5, Macro F1 score: 0.4913331446956467 and Micro F1 Score 0.86909604519774\n",
      "Hypercholesterolemia\n",
      "(502, 600) (502,) Counter({1.0: 262, 0.0: 240})\n",
      "For n=1, Macro F1 score: 0.5997397220128751 and Micro F1 Score 0.6058039215686274\n",
      "For n=5, Macro F1 score: 0.6286536074061057 and Micro F1 Score 0.6336470588235292\n",
      "Hypertension\n",
      "(531, 600) (531,) Counter({1.0: 428, 0.0: 103})\n",
      "For n=1, Macro F1 score: 0.5145295225767164 and Micro F1 Score 0.7287910552061495\n",
      "For n=5, Macro F1 score: 0.45735266627424387 and Micro F1 Score 0.7910552061495457\n",
      "Hypertriglyceridemia\n",
      "(587, 600) (587,) Counter({0.0: 554, 1.0: 33})\n",
      "For n=1, Macro F1 score: 0.5231967030617828 and Micro F1 Score 0.9200467562828756\n",
      "For n=5, Macro F1 score: 0.4854267614497737 and Micro F1 Score 0.9438924605493864\n",
      "OA\n",
      "(565, 600) (565,) Counter({0.0: 467, 1.0: 98})\n",
      "For n=1, Macro F1 score: 0.5486737112053375 and Micro F1 Score 0.7768796992481203\n",
      "For n=5, Macro F1 score: 0.5114754594091988 and Micro F1 Score 0.8193609022556393\n",
      "Obesity\n",
      "(553, 600) (553,) Counter({0.0: 314, 1.0: 239})\n",
      "For n=1, Macro F1 score: 0.5581541364314759 and Micro F1 Score 0.5822077922077922\n",
      "For n=5, Macro F1 score: 0.6205889639967161 and Micro F1 Score 0.654577922077922\n",
      "OSA\n",
      "(590, 600) (590,) Counter({0.0: 506, 1.0: 84})\n",
      "For n=1, Macro F1 score: 0.6171915733468618 and Micro F1 Score 0.8372881355932205\n",
      "For n=5, Macro F1 score: 0.5455956870096166 and Micro F1 Score 0.8661016949152541\n",
      "PVD\n",
      "(556, 600) (556,) Counter({0.0: 469, 1.0: 87})\n",
      "For n=1, Macro F1 score: 0.5599004708797071 and Micro F1 Score 0.7806818181818181\n",
      "For n=5, Macro F1 score: 0.5582567783297845 and Micro F1 Score 0.8418831168831169\n",
      "Venous-Insufficiency\n",
      "(526, 600) (526,) Counter({0.0: 482, 1.0: 44})\n",
      "For n=1, Macro F1 score: 0.5547791351205053 and Micro F1 Score 0.8803701015965167\n",
      "For n=5, Macro F1 score: 0.5047355498779927 and Micro F1 Score 0.9164731494920174\n"
     ]
    }
   ],
   "source": [
    "with open(\"./results/tf-idf-features/performance_KNN_SelectKBest.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([column_headings[0], column_headings[1], column_headings[2], column_headings[3], column_headings[4]])\n",
    "\n",
    "all_f1_macro1_scores = []\n",
    "all_f1_micro1_scores = []\n",
    "\n",
    "all_f1_macro5_scores = []\n",
    "all_f1_micro5_scores = []\n",
    "\n",
    "for morbidity in morbidities:\n",
    "    print(morbidity)\n",
    "    train_preprocessed_df = pd.read_csv('./dataset/train/train_data_intuitive_preprocessed.csv')\n",
    "    train_preprocessed_df = train_preprocessed_df[train_preprocessed_df[morbidity].isin([1.0, 0.0])]\n",
    "\n",
    "    X, Y, words = TFIDFFeatureGeneration(train_preprocessed_df, morbidity).tf_idf_matrix_gen()\n",
    "\n",
    "    # add KFold cross validation\n",
    "    skf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    f1_macro_list1 = []\n",
    "    f1_micro_list1 = []\n",
    "    f1_macro_list5 = []\n",
    "    f1_micro_list5 = []\n",
    "    for train_idx, val_idx in skf.split(X, Y):\n",
    "        X_train_fold, Y_train_fold = X[train_idx], Y[train_idx]\n",
    "        X_val_fold, Y_val_fold = X[val_idx], Y[val_idx]\n",
    "\n",
    "        # Training KNN using TF-IDF Representation\n",
    "        knn1_obj = KNN(X_train_fold, Y_train_fold, X_val_fold, Y_val_fold, 1, 100)\n",
    "        knn1_obj.feature_selection_SelectKBest()\n",
    "        knn1_obj.train()\n",
    "\n",
    "        f1_macro1, f1_micro1 = knn1_obj.test_and_evaluate()\n",
    "\n",
    "        f1_macro_list1.append(f1_macro1)\n",
    "        f1_micro_list1.append(f1_micro1)\n",
    "\n",
    "        knn5_obj = KNN(X_train_fold, Y_train_fold, X_val_fold, Y_val_fold, 5, 100)\n",
    "        knn5_obj.feature_selection_SelectKBest()\n",
    "        knn5_obj.train()\n",
    "\n",
    "        f1_macro5, f1_micro5 = knn5_obj.test_and_evaluate()\n",
    "\n",
    "        f1_macro_list5.append(f1_macro5)\n",
    "        f1_micro_list5.append(f1_micro5)\n",
    "\n",
    "    f1_macro1 = np.mean(f1_macro_list1)\n",
    "    f1_micro1 = np.mean(f1_micro_list1)\n",
    "    f1_macro5 = np.mean(f1_macro_list5)\n",
    "    f1_micro5 = np.mean(f1_micro_list5)\n",
    "\n",
    "    print(f\"For n=1, Macro F1 score: {f1_macro1} and Micro F1 Score {f1_micro1}\")\n",
    "    print(f\"For n=5, Macro F1 score: {f1_macro5} and Micro F1 Score {f1_micro5}\")\n",
    "\n",
    "    row_heading = morbidity\n",
    "\n",
    "    # data to be written to the CSV file\n",
    "    data = [f1_macro1, f1_micro1, f1_macro5, f1_micro5]\n",
    "    all_f1_macro1_scores.append(f1_macro1)\n",
    "    all_f1_micro1_scores.append(f1_micro1)\n",
    "\n",
    "    all_f1_macro5_scores.append(f1_macro5)\n",
    "    all_f1_micro5_scores.append(f1_micro5)\n",
    "\n",
    "\n",
    "    with open(\"./results/tf-idf-features/performance_KNN_SelectKBest.csv\", \"a\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        row = [row_heading]\n",
    "        row.extend(data)\n",
    "        writer.writerow(row)\n",
    "\n",
    "with open(\"./results/tf-idf-features/performance_KNN_SelectKBest.csv\", \"a\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    row = [\"Overall-Average\"]\n",
    "    row.extend([\n",
    "        sum(all_f1_macro1_scores)/len(all_f1_macro1_scores),  sum(all_f1_micro1_scores)/len(all_f1_micro1_scores),\n",
    "        sum(all_f1_macro5_scores)/len(all_f1_macro5_scores),  sum(all_f1_micro5_scores)/len(all_f1_micro5_scores) \n",
    "                ])\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asthma\n",
      "(572, 600) (572,) Counter({0.0: 502, 1.0: 70})\n",
      "For n=1, Macro F1 score: 0.5278217949096919 and Micro F1 Score 0.8688747731397459\n",
      "For n=5, Macro F1 score: 0.505398472032971 and Micro F1 Score 0.8828493647912886\n",
      "CAD\n",
      "(548, 600) (548,) Counter({1.0: 325, 0.0: 223})\n",
      "For n=1, Macro F1 score: 0.6824731264416342 and Micro F1 Score 0.6935353535353536\n",
      "For n=5, Macro F1 score: 0.6968978475281808 and Micro F1 Score 0.7079124579124579\n",
      "CHF\n",
      "(243, 600) (243,) Counter({1.0: 243})\n",
      "For n=1, Macro F1 score: 1.0 and Micro F1 Score 1.0\n",
      "For n=5, Macro F1 score: 1.0 and Micro F1 Score 1.0\n",
      "Depression\n",
      "(582, 600) (582,) Counter({0.0: 460, 1.0: 122})\n",
      "For n=1, Macro F1 score: 0.5423872024531897 and Micro F1 Score 0.7578609000584453\n",
      "For n=5, Macro F1 score: 0.5069387078275198 and Micro F1 Score 0.7869666861484512\n",
      "Diabetes\n",
      "(567, 600) (567,) Counter({1.0: 396, 0.0: 171})\n",
      "For n=1, Macro F1 score: 0.6568890734896928 and Micro F1 Score 0.725062656641604\n",
      "For n=5, Macro F1 score: 0.6044734403546814 and Micro F1 Score 0.7303258145363409\n",
      "Gallstones\n",
      "(593, 600) (593,) Counter({0.0: 506, 1.0: 87})\n",
      "For n=1, Macro F1 score: 0.5148105876688331 and Micro F1 Score 0.8076271186440678\n",
      "For n=5, Macro F1 score: 0.46844139504422344 and Micro F1 Score 0.8481355932203389\n",
      "GERD\n",
      "(487, 600) (487,) Counter({0.0: 372, 1.0: 115})\n",
      "For n=1, Macro F1 score: 0.4836668516051558 and Micro F1 Score 0.7001700680272109\n",
      "For n=5, Macro F1 score: 0.44449524359110865 and Micro F1 Score 0.7556547619047619\n",
      "Gout\n",
      "(596, 600) (596,) Counter({0.0: 518, 1.0: 78})\n",
      "For n=1, Macro F1 score: 0.5275740088177275 and Micro F1 Score 0.8288135593220339\n",
      "For n=5, Macro F1 score: 0.5299201234053821 and Micro F1 Score 0.8724858757062147\n",
      "Hypercholesterolemia\n",
      "(502, 600) (502,) Counter({1.0: 262, 0.0: 240})\n",
      "For n=1, Macro F1 score: 0.6237948579564023 and Micro F1 Score 0.6277254901960784\n",
      "For n=5, Macro F1 score: 0.6435454830659978 and Micro F1 Score 0.6495294117647059\n",
      "Hypertension\n",
      "(531, 600) (531,) Counter({1.0: 428, 0.0: 103})\n",
      "For n=1, Macro F1 score: 0.5086619191550443 and Micro F1 Score 0.7663871418588399\n",
      "For n=5, Macro F1 score: 0.4646310624163732 and Micro F1 Score 0.802375960866527\n",
      "Hypertriglyceridemia\n",
      "(587, 600) (587,) Counter({0.0: 554, 1.0: 33})\n",
      "For n=1, Macro F1 score: 0.4937862797731724 and Micro F1 Score 0.9285505552308593\n",
      "For n=5, Macro F1 score: 0.4854267614497737 and Micro F1 Score 0.9438924605493864\n",
      "OA\n",
      "(565, 600) (565,) Counter({0.0: 467, 1.0: 98})\n",
      "For n=1, Macro F1 score: 0.5240982367322962 and Micro F1 Score 0.7893170426065164\n",
      "For n=5, Macro F1 score: 0.5248283627470443 and Micro F1 Score 0.8317355889724309\n",
      "Obesity\n",
      "(553, 600) (553,) Counter({0.0: 314, 1.0: 239})\n",
      "For n=1, Macro F1 score: 0.5886386594267963 and Micro F1 Score 0.615\n",
      "For n=5, Macro F1 score: 0.6195909676116254 and Micro F1 Score 0.6602272727272728\n",
      "OSA\n",
      "(590, 600) (590,) Counter({0.0: 506, 1.0: 84})\n",
      "For n=1, Macro F1 score: 0.6351710346785728 and Micro F1 Score 0.8745762711864407\n",
      "For n=5, Macro F1 score: 0.5422602043860085 and Micro F1 Score 0.8677966101694915\n",
      "PVD\n",
      "(556, 600) (556,) Counter({0.0: 469, 1.0: 87})\n",
      "For n=1, Macro F1 score: 0.5468606680529635 and Micro F1 Score 0.8021103896103897\n",
      "For n=5, Macro F1 score: 0.5366332497345095 and Micro F1 Score 0.8507142857142858\n",
      "Venous-Insufficiency\n",
      "(526, 600) (526,) Counter({0.0: 482, 1.0: 44})\n",
      "For n=1, Macro F1 score: 0.47384012102541445 and Micro F1 Score 0.9012699564586356\n",
      "For n=5, Macro F1 score: 0.4927712393004532 and Micro F1 Score 0.9183236574746008\n"
     ]
    }
   ],
   "source": [
    "with open(\"./results/tf-idf-features/performance_KNN_ExtraTreesClassifier.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([column_headings[0], column_headings[1], column_headings[2], column_headings[3], column_headings[4]])\n",
    "\n",
    "all_f1_macro1_scores = []\n",
    "all_f1_micro1_scores = []\n",
    "\n",
    "all_f1_macro5_scores = []\n",
    "all_f1_micro5_scores = []\n",
    "\n",
    "for morbidity in morbidities:\n",
    "    print(morbidity)\n",
    "    train_preprocessed_df = pd.read_csv('./dataset/train/train_data_intuitive_preprocessed.csv')\n",
    "    train_preprocessed_df = train_preprocessed_df[train_preprocessed_df[morbidity].isin([1.0, 0.0])]\n",
    "\n",
    "    X, Y, words = TFIDFFeatureGeneration(train_preprocessed_df, morbidity).tf_idf_matrix_gen()\n",
    "\n",
    "    # add KFold cross validation\n",
    "    skf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    f1_macro_list1 = []\n",
    "    f1_micro_list1 = []\n",
    "    f1_macro_list5 = []\n",
    "    f1_micro_list5 = []\n",
    "    for train_idx, val_idx in skf.split(X, Y):\n",
    "        X_train_fold, Y_train_fold = X[train_idx], Y[train_idx]\n",
    "        X_val_fold, Y_val_fold = X[val_idx], Y[val_idx]\n",
    "\n",
    "        # Training KNN using TF-IDF Representation\n",
    "        knn1_obj = KNN(X_train_fold, Y_train_fold, X_val_fold, Y_val_fold, 1, 100)\n",
    "        knn1_obj.feature_selection_ExtraTreesClassifier()\n",
    "        knn1_obj.train()\n",
    "\n",
    "        f1_macro1, f1_micro1 = knn1_obj.test_and_evaluate()\n",
    "\n",
    "        f1_macro_list1.append(f1_macro1)\n",
    "        f1_micro_list1.append(f1_micro1)\n",
    "\n",
    "        knn5_obj = KNN(X_train_fold, Y_train_fold, X_val_fold, Y_val_fold, 5, 100)\n",
    "        knn5_obj.feature_selection_ExtraTreesClassifier()\n",
    "        knn5_obj.train()\n",
    "\n",
    "        f1_macro5, f1_micro5 = knn5_obj.test_and_evaluate()\n",
    "\n",
    "        f1_macro_list5.append(f1_macro5)\n",
    "        f1_micro_list5.append(f1_micro5)\n",
    "\n",
    "    f1_macro1 = np.mean(f1_macro_list1)\n",
    "    f1_micro1 = np.mean(f1_micro_list1)\n",
    "    f1_macro5 = np.mean(f1_macro_list5)\n",
    "    f1_micro5 = np.mean(f1_micro_list5)\n",
    "\n",
    "    print(f\"For n=1, Macro F1 score: {f1_macro1} and Micro F1 Score {f1_micro1}\")\n",
    "    print(f\"For n=5, Macro F1 score: {f1_macro5} and Micro F1 Score {f1_micro5}\")\n",
    "\n",
    "    row_heading = morbidity\n",
    "\n",
    "    # data to be written to the CSV file\n",
    "    data = [f1_macro1, f1_micro1, f1_macro5, f1_micro5]\n",
    "    all_f1_macro1_scores.append(f1_macro1)\n",
    "    all_f1_micro1_scores.append(f1_micro1)\n",
    "\n",
    "    all_f1_macro5_scores.append(f1_macro5)\n",
    "    all_f1_micro5_scores.append(f1_micro5)\n",
    "\n",
    "\n",
    "    with open(\"./results/tf-idf-features/performance_KNN_ExtraTreesClassifier.csv\", \"a\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        row = [row_heading]\n",
    "        row.extend(data)\n",
    "        writer.writerow(row)\n",
    "\n",
    "with open(\"./results/tf-idf-features/performance_KNN_ExtraTreesClassifier.csv\", \"a\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    row = [\"Overall-Average\"]\n",
    "    row.extend([\n",
    "        sum(all_f1_macro1_scores)/len(all_f1_macro1_scores),  sum(all_f1_micro1_scores)/len(all_f1_micro1_scores),\n",
    "        sum(all_f1_macro5_scores)/len(all_f1_macro5_scores),  sum(all_f1_micro5_scores)/len(all_f1_micro5_scores) \n",
    "                ])\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asthma\n",
      "(572, 600) (572,) Counter({0.0: 502, 1.0: 70})\n",
      "For n=1, Macro F1 score: 0.5278217949096919 and Micro F1 Score 0.8688747731397459\n",
      "For n=5, Macro F1 score: 0.505398472032971 and Micro F1 Score 0.8828493647912886\n",
      "CAD\n",
      "(548, 600) (548,) Counter({1.0: 325, 0.0: 223})\n",
      "For n=1, Macro F1 score: 0.6824731264416342 and Micro F1 Score 0.6935353535353536\n",
      "For n=5, Macro F1 score: 0.6968978475281808 and Micro F1 Score 0.7079124579124579\n",
      "CHF\n",
      "(243, 600) (243,) Counter({1.0: 243})\n",
      "For n=1, Macro F1 score: 1.0 and Micro F1 Score 1.0\n",
      "For n=5, Macro F1 score: 1.0 and Micro F1 Score 1.0\n",
      "Depression\n",
      "(582, 600) (582,) Counter({0.0: 460, 1.0: 122})\n",
      "For n=1, Macro F1 score: 0.5423872024531897 and Micro F1 Score 0.7578609000584453\n",
      "For n=5, Macro F1 score: 0.5069387078275198 and Micro F1 Score 0.7869666861484512\n",
      "Diabetes\n",
      "(567, 600) (567,) Counter({1.0: 396, 0.0: 171})\n",
      "For n=1, Macro F1 score: 0.6568890734896928 and Micro F1 Score 0.725062656641604\n",
      "For n=5, Macro F1 score: 0.6044734403546814 and Micro F1 Score 0.7303258145363409\n",
      "Gallstones\n",
      "(593, 600) (593,) Counter({0.0: 506, 1.0: 87})\n",
      "For n=1, Macro F1 score: 0.5148105876688331 and Micro F1 Score 0.8076271186440678\n",
      "For n=5, Macro F1 score: 0.46844139504422344 and Micro F1 Score 0.8481355932203389\n",
      "GERD\n",
      "(487, 600) (487,) Counter({0.0: 372, 1.0: 115})\n",
      "For n=1, Macro F1 score: 0.4836668516051558 and Micro F1 Score 0.7001700680272109\n",
      "For n=5, Macro F1 score: 0.44449524359110865 and Micro F1 Score 0.7556547619047619\n",
      "Gout\n",
      "(596, 600) (596,) Counter({0.0: 518, 1.0: 78})\n",
      "For n=1, Macro F1 score: 0.5275740088177275 and Micro F1 Score 0.8288135593220339\n",
      "For n=5, Macro F1 score: 0.5299201234053821 and Micro F1 Score 0.8724858757062147\n",
      "Hypercholesterolemia\n",
      "(502, 600) (502,) Counter({1.0: 262, 0.0: 240})\n",
      "For n=1, Macro F1 score: 0.6237948579564023 and Micro F1 Score 0.6277254901960784\n",
      "For n=5, Macro F1 score: 0.6435454830659978 and Micro F1 Score 0.6495294117647059\n",
      "Hypertension\n",
      "(531, 600) (531,) Counter({1.0: 428, 0.0: 103})\n",
      "For n=1, Macro F1 score: 0.5086619191550443 and Micro F1 Score 0.7663871418588399\n",
      "For n=5, Macro F1 score: 0.4646310624163732 and Micro F1 Score 0.802375960866527\n",
      "Hypertriglyceridemia\n",
      "(587, 600) (587,) Counter({0.0: 554, 1.0: 33})\n",
      "For n=1, Macro F1 score: 0.4937862797731724 and Micro F1 Score 0.9285505552308593\n",
      "For n=5, Macro F1 score: 0.4854267614497737 and Micro F1 Score 0.9438924605493864\n",
      "OA\n",
      "(565, 600) (565,) Counter({0.0: 467, 1.0: 98})\n",
      "For n=1, Macro F1 score: 0.5240982367322962 and Micro F1 Score 0.7893170426065164\n",
      "For n=5, Macro F1 score: 0.5248283627470443 and Micro F1 Score 0.8317355889724309\n",
      "Obesity\n",
      "(553, 600) (553,) Counter({0.0: 314, 1.0: 239})\n",
      "For n=1, Macro F1 score: 0.5886386594267963 and Micro F1 Score 0.615\n",
      "For n=5, Macro F1 score: 0.6195909676116254 and Micro F1 Score 0.6602272727272728\n",
      "OSA\n",
      "(590, 600) (590,) Counter({0.0: 506, 1.0: 84})\n",
      "For n=1, Macro F1 score: 0.6351710346785728 and Micro F1 Score 0.8745762711864407\n",
      "For n=5, Macro F1 score: 0.5422602043860085 and Micro F1 Score 0.8677966101694915\n",
      "PVD\n",
      "(556, 600) (556,) Counter({0.0: 469, 1.0: 87})\n",
      "For n=1, Macro F1 score: 0.5468606680529635 and Micro F1 Score 0.8021103896103897\n",
      "For n=5, Macro F1 score: 0.5366332497345095 and Micro F1 Score 0.8507142857142858\n",
      "Venous-Insufficiency\n",
      "(526, 600) (526,) Counter({0.0: 482, 1.0: 44})\n",
      "For n=1, Macro F1 score: 0.47384012102541445 and Micro F1 Score 0.9012699564586356\n",
      "For n=5, Macro F1 score: 0.4927712393004532 and Micro F1 Score 0.9183236574746008\n"
     ]
    }
   ],
   "source": [
    "with open(\"./results/tf-idf-features/performance_KNN_ExtraTreesClassifier.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([column_headings[0], column_headings[1], column_headings[2], column_headings[3], column_headings[4]])\n",
    "\n",
    "all_f1_macro1_scores = []\n",
    "all_f1_micro1_scores = []\n",
    "\n",
    "all_f1_macro5_scores = []\n",
    "all_f1_micro5_scores = []\n",
    "\n",
    "for morbidity in morbidities:\n",
    "    print(morbidity)\n",
    "    train_preprocessed_df = pd.read_csv('./dataset/train/train_data_intuitive_preprocessed.csv')\n",
    "    train_preprocessed_df = train_preprocessed_df[train_preprocessed_df[morbidity].isin([1.0, 0.0])]\n",
    "\n",
    "    X, Y, words = TFIDFFeatureGeneration(train_preprocessed_df, morbidity).tf_idf_matrix_gen()\n",
    "\n",
    "    # add KFold cross validation\n",
    "    skf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    f1_macro_list1 = []\n",
    "    f1_micro_list1 = []\n",
    "    f1_macro_list5 = []\n",
    "    f1_micro_list5 = []\n",
    "    for train_idx, val_idx in skf.split(X, Y):\n",
    "        X_train_fold, Y_train_fold = X[train_idx], Y[train_idx]\n",
    "        X_val_fold, Y_val_fold = X[val_idx], Y[val_idx]\n",
    "\n",
    "        # Training KNN using TF-IDF Representation\n",
    "        knn1_obj = KNN(X_train_fold, Y_train_fold, X_val_fold, Y_val_fold, 1, 100)\n",
    "        knn1_obj.feature_selection_ExtraTreesClassifier()\n",
    "        knn1_obj.train()\n",
    "\n",
    "        f1_macro1, f1_micro1 = knn1_obj.test_and_evaluate()\n",
    "\n",
    "        f1_macro_list1.append(f1_macro1)\n",
    "        f1_micro_list1.append(f1_micro1)\n",
    "\n",
    "        knn5_obj = KNN(X_train_fold, Y_train_fold, X_val_fold, Y_val_fold, 5, 100)\n",
    "        knn5_obj.feature_selection_ExtraTreesClassifier()\n",
    "        knn5_obj.train()\n",
    "\n",
    "        f1_macro5, f1_micro5 = knn5_obj.test_and_evaluate()\n",
    "\n",
    "        f1_macro_list5.append(f1_macro5)\n",
    "        f1_micro_list5.append(f1_micro5)\n",
    "\n",
    "    f1_macro1 = np.mean(f1_macro_list1)\n",
    "    f1_micro1 = np.mean(f1_micro_list1)\n",
    "    f1_macro5 = np.mean(f1_macro_list5)\n",
    "    f1_micro5 = np.mean(f1_micro_list5)\n",
    "\n",
    "    print(f\"For n=1, Macro F1 score: {f1_macro1} and Micro F1 Score {f1_micro1}\")\n",
    "    print(f\"For n=5, Macro F1 score: {f1_macro5} and Micro F1 Score {f1_micro5}\")\n",
    "\n",
    "    row_heading = morbidity\n",
    "\n",
    "    # data to be written to the CSV file\n",
    "    data = [f1_macro1, f1_micro1, f1_macro5, f1_micro5]\n",
    "    all_f1_macro1_scores.append(f1_macro1)\n",
    "    all_f1_micro1_scores.append(f1_micro1)\n",
    "\n",
    "    all_f1_macro5_scores.append(f1_macro5)\n",
    "    all_f1_micro5_scores.append(f1_micro5)\n",
    "\n",
    "\n",
    "    with open(\"./results/tf-idf-features/performance_KNN_ExtraTreesClassifier.csv\", \"a\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        row = [row_heading]\n",
    "        row.extend(data)\n",
    "        writer.writerow(row)\n",
    "\n",
    "with open(\"./results/tf-idf-features/performance_KNN_ExtraTreesClassifier.csv\", \"a\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    row = [\"Overall-Average\"]\n",
    "    row.extend([\n",
    "        sum(all_f1_macro1_scores)/len(all_f1_macro1_scores),  sum(all_f1_micro1_scores)/len(all_f1_micro1_scores),\n",
    "        sum(all_f1_macro5_scores)/len(all_f1_macro5_scores),  sum(all_f1_micro5_scores)/len(all_f1_micro5_scores) \n",
    "                ])\n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asthma\n",
      "(572, 600) (572,) Counter({0.0: 502, 1.0: 70})\n",
      "For n=1, Macro F1 score: 0.9094597195218244 and Micro F1 Score 0.9650030248033878\n",
      "For n=5, Macro F1 score: 0.8476552107167418 and Micro F1 Score 0.9475196612220204\n",
      "CAD\n",
      "(548, 600) (548,) Counter({1.0: 325, 0.0: 223})\n",
      "For n=1, Macro F1 score: 0.824406325072748 and Micro F1 Score 0.8284511784511785\n",
      "For n=5, Macro F1 score: 0.8511751737633242 and Micro F1 Score 0.8556565656565656\n",
      "CHF\n",
      "(243, 600) (243,) Counter({1.0: 243})\n",
      "For n=1, Macro F1 score: 1 and Micro F1 Score 1\n",
      "For n=5, Macro F1 score: 1 and Micro F1 Score 1\n",
      "Depression\n",
      "(582, 600) (582,) Counter({0.0: 460, 1.0: 122})\n",
      "For n=1, Macro F1 score: 0.6887780746824912 and Micro F1 Score 0.7990648743424897\n",
      "For n=5, Macro F1 score: 0.7203267817584003 and Micro F1 Score 0.8505260081823496\n",
      "Diabetes\n",
      "(567, 600) (567,) Counter({1.0: 396, 0.0: 171})\n",
      "For n=1, Macro F1 score: 0.8737822893538032 and Micro F1 Score 0.8993734335839599\n",
      "For n=5, Macro F1 score: 0.862032564768108 and Micro F1 Score 0.8834899749373433\n",
      "Gallstones\n",
      "(593, 600) (593,) Counter({0.0: 506, 1.0: 87})\n",
      "For n=1, Macro F1 score: 0.5065892082010224 and Micro F1 Score 0.7604802259887006\n",
      "For n=5, Macro F1 score: 0.5056616825241497 and Micro F1 Score 0.8363276836158192\n",
      "GERD\n",
      "(487, 600) (487,) Counter({0.0: 372, 1.0: 115})\n",
      "For n=1, Macro F1 score: 0.5924522619623029 and Micro F1 Score 0.7147959183673469\n",
      "For n=5, Macro F1 score: 0.5859462887359956 and Micro F1 Score 0.7680697278911564\n",
      "Gout\n",
      "(596, 600) (596,) Counter({0.0: 518, 1.0: 78})\n",
      "For n=1, Macro F1 score: 0.5968610116407128 and Micro F1 Score 0.8205084745762712\n",
      "For n=5, Macro F1 score: 0.5347959797492509 and Micro F1 Score 0.8355932203389832\n",
      "Hypercholesterolemia\n",
      "(502, 600) (502,) Counter({1.0: 262, 0.0: 240})\n",
      "For n=1, Macro F1 score: 0.7609667705825739 and Micro F1 Score 0.7647450980392156\n",
      "For n=5, Macro F1 score: 0.7688103863120819 and Micro F1 Score 0.7728235294117647\n",
      "Hypertension\n",
      "(531, 600) (531,) Counter({1.0: 428, 0.0: 103})\n",
      "For n=1, Macro F1 score: 0.7541009564636909 and Micro F1 Score 0.843675751222921\n",
      "For n=5, Macro F1 score: 0.8187159094998101 and Micro F1 Score 0.8926974143955277\n",
      "Hypertriglyceridemia\n",
      "(587, 600) (587,) Counter({0.0: 554, 1.0: 33})\n",
      "For n=1, Macro F1 score: 0.5168872898324002 and Micro F1 Score 0.9217416715371127\n",
      "For n=5, Macro F1 score: 0.484027559861785 and Micro F1 Score 0.9388077147866746\n",
      "OA\n",
      "(565, 600) (565,) Counter({0.0: 467, 1.0: 98})\n",
      "For n=1, Macro F1 score: 0.5627512752787168 and Micro F1 Score 0.743483709273183\n",
      "For n=5, Macro F1 score: 0.6161689795267803 and Micro F1 Score 0.8230889724310776\n",
      "Obesity\n",
      "(553, 600) (553,) Counter({0.0: 314, 1.0: 239})\n",
      "For n=1, Macro F1 score: 0.8113372164848125 and Micro F1 Score 0.8210064935064935\n",
      "For n=5, Macro F1 score: 0.8205306744091502 and Micro F1 Score 0.8336038961038961\n",
      "OSA\n",
      "(590, 600) (590,) Counter({0.0: 506, 1.0: 84})\n",
      "For n=1, Macro F1 score: 0.7974594223089112 and Micro F1 Score 0.9067796610169492\n",
      "For n=5, Macro F1 score: 0.8094231238374803 and Micro F1 Score 0.9203389830508474\n",
      "PVD\n",
      "(556, 600) (556,) Counter({0.0: 469, 1.0: 87})\n",
      "For n=1, Macro F1 score: 0.7211557618169183 and Micro F1 Score 0.8650974025974026\n",
      "For n=5, Macro F1 score: 0.747255696488511 and Micro F1 Score 0.8937987012987014\n",
      "Venous-Insufficiency\n",
      "(526, 600) (526,) Counter({0.0: 482, 1.0: 44})\n",
      "For n=1, Macro F1 score: 0.5826908391787778 and Micro F1 Score 0.893577648766328\n",
      "For n=5, Macro F1 score: 0.5218676766410892 and Micro F1 Score 0.9126632801161104\n"
     ]
    }
   ],
   "source": [
    "with open(\"./results/tf-idf-features/performance_KNN_InfoGain.csv\", \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([column_headings[0], column_headings[1], column_headings[2], column_headings[3], column_headings[4]])\n",
    "\n",
    "all_f1_macro1_scores = []\n",
    "all_f1_micro1_scores = []\n",
    "\n",
    "all_f1_macro5_scores = []\n",
    "all_f1_micro5_scores = []\n",
    "\n",
    "for morbidity in morbidities:\n",
    "    print(morbidity)\n",
    "    train_preprocessed_df = pd.read_csv('./dataset/train/train_data_intuitive_preprocessed.csv')\n",
    "    train_preprocessed_df = train_preprocessed_df[train_preprocessed_df[morbidity].isin([1.0, 0.0])]\n",
    "\n",
    "    X, Y, words = TFIDFFeatureGeneration(train_preprocessed_df, morbidity).tf_idf_matrix_gen()\n",
    "\n",
    "    # add KFold cross validation\n",
    "    skf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    if len(collections.Counter(list(Y)).keys()) < 2:\n",
    "        f1_macro1 = 1\n",
    "        f1_micro1 = 1\n",
    "        f1_macro5 = 1\n",
    "        f1_micro5 = 1\n",
    "    else:\n",
    "\n",
    "        f1_macro_list1 = []\n",
    "        f1_micro_list1 = []\n",
    "        f1_macro_list5 = []\n",
    "        f1_micro_list5 = []\n",
    "        for train_idx, val_idx in skf.split(X, Y):\n",
    "            X_train_fold, Y_train_fold = X[train_idx], Y[train_idx]\n",
    "            X_val_fold, Y_val_fold = X[val_idx], Y[val_idx]\n",
    "\n",
    "            # Training KNN using TF-IDF Representation\n",
    "            knn1_obj = KNN(X_train_fold, Y_train_fold, X_val_fold, Y_val_fold, 1, 100)\n",
    "            knn1_obj.feature_selection_InfoGainAttributeEval(morbidity)\n",
    "            knn1_obj.train()\n",
    "\n",
    "            f1_macro1, f1_micro1 = knn1_obj.test_and_evaluate()\n",
    "\n",
    "            f1_macro_list1.append(f1_macro1)\n",
    "            f1_micro_list1.append(f1_micro1)\n",
    "\n",
    "            knn5_obj = KNN(X_train_fold, Y_train_fold, X_val_fold, Y_val_fold, 5, 100)\n",
    "            knn5_obj.feature_selection_InfoGainAttributeEval(morbidity)\n",
    "            knn5_obj.train()\n",
    "\n",
    "            f1_macro5, f1_micro5 = knn5_obj.test_and_evaluate()\n",
    "\n",
    "            f1_macro_list5.append(f1_macro5)\n",
    "            f1_micro_list5.append(f1_micro5)\n",
    "\n",
    "        f1_macro1 = np.mean(f1_macro_list1)\n",
    "        f1_micro1 = np.mean(f1_micro_list1)\n",
    "        f1_macro5 = np.mean(f1_macro_list5)\n",
    "        f1_micro5 = np.mean(f1_micro_list5)\n",
    "\n",
    "    print(f\"For n=1, Macro F1 score: {f1_macro1} and Micro F1 Score {f1_micro1}\")\n",
    "    print(f\"For n=5, Macro F1 score: {f1_macro5} and Micro F1 Score {f1_micro5}\")\n",
    "\n",
    "    row_heading = morbidity\n",
    "\n",
    "    # data to be written to the CSV file\n",
    "    data = [f1_macro1, f1_micro1, f1_macro5, f1_micro5]\n",
    "    all_f1_macro1_scores.append(f1_macro1)\n",
    "    all_f1_micro1_scores.append(f1_micro1)\n",
    "\n",
    "    all_f1_macro5_scores.append(f1_macro5)\n",
    "    all_f1_micro5_scores.append(f1_micro5)\n",
    "\n",
    "\n",
    "    with open(\"./results/tf-idf-features/performance_KNN_InfoGain.csv\", \"a\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        row = [row_heading]\n",
    "        row.extend(data)\n",
    "        writer.writerow(row)\n",
    "\n",
    "with open(\"./results/tf-idf-features/performance_KNN_InfoGain.csv\", \"a\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    row = [\"Overall-Average\"]\n",
    "    row.extend([\n",
    "        sum(all_f1_macro1_scores)/len(all_f1_macro1_scores),  sum(all_f1_micro1_scores)/len(all_f1_micro1_scores),\n",
    "        sum(all_f1_macro5_scores)/len(all_f1_macro5_scores),  sum(all_f1_micro5_scores)/len(all_f1_micro5_scores) \n",
    "                ])\n",
    "    writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
